import CodeExampleCPP from './_code_example_cpp.mdx';
import CodeExamplePython from './_code_example_python.mdx';

## Run Model Using OpenVINO GenAI

OpenVINO GenAI introduces the [`VLMPipeline`](https://docs.openvino.ai/2025/api/genai_api/_autosummary/openvino_genai.VLMPipeline.html) pipeline for inference of multimodal text-generation Vision Language Models (VLMs).
It can generate text from a text prompt and images as inputs.

<LanguageTabs>
    <TabItemPython>
        <Tabs groupId="device">
            <TabItem label="CPU" value="cpu">
                <CodeExamplePython device="CPU" />
            </TabItem>
            <TabItem label="GPU" value="gpu">
                <CodeExamplePython device="GPU" />
            </TabItem>
        </Tabs>
    </TabItemPython>
    <TabItemCpp>
        <Tabs groupId="device">
            <TabItem label="CPU" value="cpu">
                <CodeExampleCPP device="CPU" />
            </TabItem>
            <TabItem label="GPU" value="gpu">
                <CodeExampleCPP device="GPU" />
            </TabItem>
        </Tabs>
    </TabItemCpp>
</LanguageTabs>

:::tip

Use CPU or GPU as devices without any other code change.

:::
